{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8rLafAgGMBL"
      },
      "source": [
        "#Initial Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D84P_db8FnSG",
        "outputId": "4de5cd8e-0d41-4e83-970f-9a58dddaaf72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m103.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.13.4 tokenizers-0.13.3 transformers-4.28.1\n"
          ]
        }
      ],
      "source": [
        "pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5aBpug_CFGNj"
      },
      "outputs": [],
      "source": [
        "#import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQxh9NUDGKbE",
        "outputId": "4f30632c-aa19-4b4a-d03e-a63662c3655d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MemTotal:       87538728 kB\n",
            "MemFree:        82909388 kB\n",
            "MemAvailable:   85889664 kB\n",
            "Buffers:          364192 kB\n",
            "Cached:          3281632 kB\n",
            "SwapCached:            0 kB\n",
            "Active:           660620 kB\n",
            "Inactive:        3535628 kB\n",
            "Active(anon):       1128 kB\n",
            "Inactive(anon):   530120 kB\n",
            "Active(file):     659492 kB\n",
            "Inactive(file):  3005508 kB\n",
            "Unevictable:           0 kB\n",
            "Mlocked:               0 kB\n",
            "SwapTotal:             0 kB\n",
            "SwapFree:              0 kB\n",
            "Dirty:            135880 kB\n",
            "Writeback:             0 kB\n",
            "AnonPages:        550244 kB\n",
            "Mapped:           270548 kB\n",
            "Shmem:              1672 kB\n",
            "KReclaimable:     125612 kB\n",
            "Slab:             184016 kB\n",
            "SReclaimable:     125612 kB\n",
            "SUnreclaim:        58404 kB\n",
            "KernelStack:        7248 kB\n",
            "PageTables:         7480 kB\n",
            "NFS_Unstable:          0 kB\n",
            "Bounce:                0 kB\n",
            "WritebackTmp:          0 kB\n",
            "CommitLimit:    43769364 kB\n",
            "Committed_AS:    4159488 kB\n",
            "VmallocTotal:   34359738367 kB\n",
            "VmallocUsed:       92024 kB\n",
            "VmallocChunk:          0 kB\n",
            "Percpu:            10752 kB\n",
            "HardwareCorrupted:     0 kB\n",
            "AnonHugePages:         0 kB\n",
            "ShmemHugePages:        0 kB\n",
            "ShmemPmdMapped:        0 kB\n",
            "FileHugePages:         0 kB\n",
            "FilePmdMapped:         0 kB\n",
            "CmaTotal:              0 kB\n",
            "CmaFree:               0 kB\n",
            "HugePages_Total:       0\n",
            "HugePages_Free:        0\n",
            "HugePages_Rsvd:        0\n",
            "HugePages_Surp:        0\n",
            "Hugepagesize:       2048 kB\n",
            "Hugetlb:               0 kB\n",
            "DirectMap4k:      189240 kB\n",
            "DirectMap2M:     4001792 kB\n",
            "DirectMap1G:    87031808 kB\n"
          ]
        }
      ],
      "source": [
        "!cat /proc/meminfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CkRqJ0gjfsp8"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgRHoMxPG7aP"
      },
      "source": [
        "#Data load and prep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oysfl0OUFhxc",
        "outputId": "8820cef5-e1d2-49f7-bcad-fda8cc03c28d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = '/content/drive/MyDrive/266Project/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "Bzpd1uprFyZp",
        "outputId": "2654d473-f77c-408c-a28f-83135f294d87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1913815, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               quote               auth  \\\n",
              "0  I'm selfish, impatient and a little insecure. ...     Marilyn Monroe   \n",
              "1  I'm selfish, impatient and a little insecure. ...     Marilyn Monroe   \n",
              "2  I'm selfish, impatient and a little insecure. ...     Marilyn Monroe   \n",
              "3  I'm selfish, impatient and a little insecure. ...     Marilyn Monroe   \n",
              "4  I'm selfish, impatient and a little insecure. ...     Marilyn Monroe   \n",
              "5  I'm selfish, impatient and a little insecure. ...     Marilyn Monroe   \n",
              "6  I'm selfish, impatient and a little insecure. ...     Marilyn Monroe   \n",
              "7  I'm selfish, impatient and a little insecure. ...     Marilyn Monroe   \n",
              "8  You've gotta dance like there's nobody watchin...  William W. Purkey   \n",
              "9  You've gotta dance like there's nobody watchin...  William W. Purkey   \n",
              "\n",
              "                           tags  \n",
              "0                          best  \n",
              "1                          life  \n",
              "2                          love  \n",
              "3  misattributed marilyn monroe  \n",
              "4                      mistakes  \n",
              "5                out of control  \n",
              "6                         truth  \n",
              "7                         worst  \n",
              "8                        heaven  \n",
              "9                          hurt  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-22ad4a6c-366c-4829-b065-841b98a3b283\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>quote</th>\n",
              "      <th>auth</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I'm selfish, impatient and a little insecure. ...</td>\n",
              "      <td>Marilyn Monroe</td>\n",
              "      <td>best</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I'm selfish, impatient and a little insecure. ...</td>\n",
              "      <td>Marilyn Monroe</td>\n",
              "      <td>life</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I'm selfish, impatient and a little insecure. ...</td>\n",
              "      <td>Marilyn Monroe</td>\n",
              "      <td>love</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I'm selfish, impatient and a little insecure. ...</td>\n",
              "      <td>Marilyn Monroe</td>\n",
              "      <td>misattributed marilyn monroe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I'm selfish, impatient and a little insecure. ...</td>\n",
              "      <td>Marilyn Monroe</td>\n",
              "      <td>mistakes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>I'm selfish, impatient and a little insecure. ...</td>\n",
              "      <td>Marilyn Monroe</td>\n",
              "      <td>out of control</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>I'm selfish, impatient and a little insecure. ...</td>\n",
              "      <td>Marilyn Monroe</td>\n",
              "      <td>truth</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>I'm selfish, impatient and a little insecure. ...</td>\n",
              "      <td>Marilyn Monroe</td>\n",
              "      <td>worst</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>You've gotta dance like there's nobody watchin...</td>\n",
              "      <td>William W. Purkey</td>\n",
              "      <td>heaven</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>You've gotta dance like there's nobody watchin...</td>\n",
              "      <td>William W. Purkey</td>\n",
              "      <td>hurt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22ad4a6c-366c-4829-b065-841b98a3b283')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-22ad4a6c-366c-4829-b065-841b98a3b283 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-22ad4a6c-366c-4829-b065-841b98a3b283');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "raw_data = pd.read_csv(path+'final_quotes.csv')\n",
        "raw_data = raw_data.dropna().drop_duplicates()\n",
        "print(raw_data.shape)\n",
        "raw_data.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "GBE14VIPZYrk",
        "outputId": "f205acd5-6e91-43fe-afe5-401afb3f7c19"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               quote               auth  \\\n",
              "0  I'm selfish, impatient and a little insecure. ...     Marilyn Monroe   \n",
              "1  I'm selfish, impatient and a little insecure. ...     Marilyn Monroe   \n",
              "2  I'm selfish, impatient and a little insecure. ...     Marilyn Monroe   \n",
              "3  I'm selfish, impatient and a little insecure. ...     Marilyn Monroe   \n",
              "4  I'm selfish, impatient and a little insecure. ...     Marilyn Monroe   \n",
              "5  I'm selfish, impatient and a little insecure. ...     Marilyn Monroe   \n",
              "6  I'm selfish, impatient and a little insecure. ...     Marilyn Monroe   \n",
              "7  I'm selfish, impatient and a little insecure. ...     Marilyn Monroe   \n",
              "8  You've gotta dance like there's nobody watchin...  William W. Purkey   \n",
              "9  You've gotta dance like there's nobody watchin...  William W. Purkey   \n",
              "\n",
              "                           tags  \\\n",
              "0                          best   \n",
              "1                          life   \n",
              "2                          love   \n",
              "3  misattributed marilyn monroe   \n",
              "4                      mistakes   \n",
              "5                out of control   \n",
              "6                         truth   \n",
              "7                         worst   \n",
              "8                        heaven   \n",
              "9                          hurt   \n",
              "\n",
              "                                       quote_context  \n",
              "0  Write a quote about best from the perspective ...  \n",
              "1  Write a quote about life from the perspective ...  \n",
              "2  Write a quote about love from the perspective ...  \n",
              "3  Write a quote about misattributed marilyn monr...  \n",
              "4  Write a quote about mistakes from the perspect...  \n",
              "5  Write a quote about out of control from the pe...  \n",
              "6  Write a quote about truth from the perspective...  \n",
              "7  Write a quote about worst from the perspective...  \n",
              "8  Write a quote about heaven from the perspectiv...  \n",
              "9  Write a quote about hurt from the perspective ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d484d9fa-10b5-435d-8291-6519362a885f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>quote</th>\n",
              "      <th>auth</th>\n",
              "      <th>tags</th>\n",
              "      <th>quote_context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I'm selfish, impatient and a little insecure. ...</td>\n",
              "      <td>Marilyn Monroe</td>\n",
              "      <td>best</td>\n",
              "      <td>Write a quote about best from the perspective ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I'm selfish, impatient and a little insecure. ...</td>\n",
              "      <td>Marilyn Monroe</td>\n",
              "      <td>life</td>\n",
              "      <td>Write a quote about life from the perspective ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I'm selfish, impatient and a little insecure. ...</td>\n",
              "      <td>Marilyn Monroe</td>\n",
              "      <td>love</td>\n",
              "      <td>Write a quote about love from the perspective ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I'm selfish, impatient and a little insecure. ...</td>\n",
              "      <td>Marilyn Monroe</td>\n",
              "      <td>misattributed marilyn monroe</td>\n",
              "      <td>Write a quote about misattributed marilyn monr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I'm selfish, impatient and a little insecure. ...</td>\n",
              "      <td>Marilyn Monroe</td>\n",
              "      <td>mistakes</td>\n",
              "      <td>Write a quote about mistakes from the perspect...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>I'm selfish, impatient and a little insecure. ...</td>\n",
              "      <td>Marilyn Monroe</td>\n",
              "      <td>out of control</td>\n",
              "      <td>Write a quote about out of control from the pe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>I'm selfish, impatient and a little insecure. ...</td>\n",
              "      <td>Marilyn Monroe</td>\n",
              "      <td>truth</td>\n",
              "      <td>Write a quote about truth from the perspective...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>I'm selfish, impatient and a little insecure. ...</td>\n",
              "      <td>Marilyn Monroe</td>\n",
              "      <td>worst</td>\n",
              "      <td>Write a quote about worst from the perspective...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>You've gotta dance like there's nobody watchin...</td>\n",
              "      <td>William W. Purkey</td>\n",
              "      <td>heaven</td>\n",
              "      <td>Write a quote about heaven from the perspectiv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>You've gotta dance like there's nobody watchin...</td>\n",
              "      <td>William W. Purkey</td>\n",
              "      <td>hurt</td>\n",
              "      <td>Write a quote about hurt from the perspective ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d484d9fa-10b5-435d-8291-6519362a885f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d484d9fa-10b5-435d-8291-6519362a885f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d484d9fa-10b5-435d-8291-6519362a885f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "#combine author and tag to create quote_context, drop quotes longer than 50 words\n",
        "#data['quote_context'] = \"Person \" + data['auth'] + ' Context ' +data['tags']\n",
        "raw_data['quote_context'] = \"Write a quote about \" + raw_data['tags'] + \" from the perspective of \" +raw_data['auth'] \n",
        "raw_data = raw_data[raw_data['quote'].str.split().apply(len) <= 50]\n",
        "raw_data.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data.head(50)"
      ],
      "metadata": {
        "id": "0gYB-YqN2ERJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "ddTsesyKd5sS",
        "outputId": "1ed1b967-8171-4c38-982c-c0158a7c479f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(165435, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             quote_context  \\\n",
              "971847   Write a quote about duty from the perspective ...   \n",
              "2407125  Write a quote about ai from the perspective of...   \n",
              "1336254  Write a quote about inefficient from the persp...   \n",
              "1197192  Write a quote about gourmet from the perspecti...   \n",
              "1415346  Write a quote about labeled from the perspecti...   \n",
              "\n",
              "                                                     quote  \n",
              "971847   The dead cannot cry out for justice. It is a d...  \n",
              "2407125  Smart CEOs should be thinking about AI and its...  \n",
              "1336254  I've seen the government up close and personal...  \n",
              "1197192  I always thought it was sad that you couldn't ...  \n",
              "1415346  There are many great wine producers from all o...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c6b129ab-a6ac-4fb1-97d5-acb58dc2d438\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>quote_context</th>\n",
              "      <th>quote</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>971847</th>\n",
              "      <td>Write a quote about duty from the perspective ...</td>\n",
              "      <td>The dead cannot cry out for justice. It is a d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2407125</th>\n",
              "      <td>Write a quote about ai from the perspective of...</td>\n",
              "      <td>Smart CEOs should be thinking about AI and its...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1336254</th>\n",
              "      <td>Write a quote about inefficient from the persp...</td>\n",
              "      <td>I've seen the government up close and personal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1197192</th>\n",
              "      <td>Write a quote about gourmet from the perspecti...</td>\n",
              "      <td>I always thought it was sad that you couldn't ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1415346</th>\n",
              "      <td>Write a quote about labeled from the perspecti...</td>\n",
              "      <td>There are many great wine producers from all o...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6b129ab-a6ac-4fb1-97d5-acb58dc2d438')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c6b129ab-a6ac-4fb1-97d5-acb58dc2d438 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c6b129ab-a6ac-4fb1-97d5-acb58dc2d438');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "data = raw_data[['quote_context','quote']]\n",
        "data = data.sample(frac=0.1)\n",
        "#data = data.sample(frac=0.0025)\n",
        "print(data.shape)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "UOKm5aLUdAjG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c096684f-64b4-4de0-8157-71cc61d6c35c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(148891, 2)\n",
            "(16544, 2)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "#split data into train/validation and test for evaluation \n",
        "data, test = train_test_split(data,test_size=0.10, shuffle=True)\n",
        "print(data.shape)\n",
        "print(test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#write prepared dataset to drive for reference\n",
        "data.to_csv(r'/content/drive/MyDrive/266Project/quotes.csv', header=None, index=None, sep=',', mode='w')\n",
        "test.to_csv(r'/content/drive/MyDrive/266Project/test_data.csv', header=None, index=None, sep=',', mode='w')"
      ],
      "metadata": {
        "id": "Uwn396raRXGV"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocessing"
      ],
      "metadata": {
        "id": "h349MdTWuLmA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "gxmjRisgaWcT"
      },
      "outputs": [],
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "\n",
        "MODEL_NAME = 'distilgpt2' \n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(MODEL_NAME)\n",
        "model = GPT2LMHeadModel.from_pretrained(MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8seTRcfTa3Ot",
        "outputId": "8851e73d-cd9d-4f0b-a7f3-ab1a9faae613"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<pad>', 'additional_special_tokens': ['<quote_context>', '<quote>']}\n"
          ]
        }
      ],
      "source": [
        "# Declare special tokens for padding and separating the context from the quote:\n",
        "SPECIAL_TOKENS_DICT = {\n",
        "    'pad_token': '<pad>',\n",
        "    'additional_special_tokens': ['<quote_context>', '<quote>'],\n",
        "}\n",
        "\n",
        "# Add these special tokens to the vocabulary and resize model's embeddings:\n",
        "tokenizer.add_special_tokens(SPECIAL_TOKENS_DICT)\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "# Show the full list of special tokens:\n",
        "print(tokenizer.special_tokens_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzxA7BD_dryi",
        "outputId": "c2786d20-fab8-4b9d-faa4-b070361c4dd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 150])\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class QuoteDataset(Dataset):\n",
        "  def __init__(self, filename, tokenizer, seq_length=150):\n",
        "\n",
        "    quote_context_tkn = tokenizer.additional_special_tokens_ids[0]\n",
        "    quote_tkn = tokenizer.additional_special_tokens_ids[1]\n",
        "    pad_tkn = tokenizer.pad_token_id\n",
        "    eos_tkn = tokenizer.eos_token_id\n",
        "\n",
        "    self.examples = []\n",
        "    with open(filename) as csvfile:\n",
        "      reader = csv.reader(csvfile)\n",
        "      for row in reader:\n",
        "      \n",
        "        # Build the quote_context and quote segments:\n",
        "        quote_context = [quote_context_tkn] + tokenizer.encode(row[0], max_length=seq_length//2-1)\n",
        "        quote = [quote_tkn] + tokenizer.encode(row[1], max_length=seq_length//2-2) + [eos_tkn]\n",
        "        \n",
        "        # Concatenate the two parts together:\n",
        "        tokens = quote_context + quote + [pad_tkn] * ( seq_length - len(quote_context) - len(quote) )\n",
        "\n",
        "        # Annotate each token with its corresponding segment:\n",
        "        segments = [quote_context_tkn] * len(quote_context) + [quote_tkn] * ( seq_length - len(quote_context) )\n",
        "\n",
        "        # Ignore the quote_context, padding, and <quote> tokens by setting their labels to -100\n",
        "        labels = [-100] * (len(quote_context)+1) + quote[1:] + [-100] * ( seq_length - len(quote_context) - len(quote) )\n",
        "\n",
        "        # Add the preprocessed example to the dataset\n",
        "        self.examples.append((tokens, segments, labels))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.examples)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    return torch.tensor(self.examples[item])\n",
        "\n",
        "\n",
        "# Build the dataset and display the dimensions of the 1st batch for verification:\n",
        "quote_dataset = QuoteDataset('quotes.csv', tokenizer)\n",
        "print(next(iter(quote_dataset)).size())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(quote_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtk-I97jtyyT",
        "outputId": "53834c42-5f16-4ebc-a2da-daccb99965e9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "148891"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "aJfgMRwpcKdf"
      },
      "outputs": [],
      "source": [
        "import math, random\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "\n",
        "# Create data indices for training and validation splits:\n",
        "\n",
        "indices = list(range(len(quote_dataset)))\n",
        "\n",
        "#random.seed(22)\n",
        "random.shuffle(indices)\n",
        "\n",
        "split = math.floor(0.1 * len(quote_dataset))\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "\n",
        "# Build the PyTorch data loaders:\n",
        "\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "val_sampler = SubsetRandomSampler(val_indices)\n",
        "\n",
        "train_loader = DataLoader(quote_dataset, batch_size=32, sampler=train_sampler)\n",
        "val_loader = DataLoader(quote_dataset, batch_size=32, sampler=val_sampler)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUpe6NnohD5D"
      },
      "source": [
        "#The Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Build Model"
      ],
      "metadata": {
        "id": "ZxuNlEp3A23s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "VLqAy6eBe1Q7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch.nn\n",
        "\n",
        "\n",
        "def fit(model, optimizer, train_dl, val_dl, epochs=1, device=torch.device('cuda')):\n",
        "\n",
        "  for i in range(epochs):\n",
        "\n",
        "    print('\\n--- Starting epoch #{} ---'.format(i))\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # These 2 lists will keep track of the batch losses and batch sizes over one epoch:\n",
        "    losses = []\n",
        "    nums = []\n",
        "\n",
        "    for xb in tqdm(train_dl, desc=\"Training\"):\n",
        "      # Move the batch to the training device:\n",
        "      inputs = xb.to(device)\n",
        "\n",
        "      # Call the model with the token ids, segment ids, and the ground truth (labels)\n",
        "      outputs = model(inputs[:,0,:], token_type_ids=inputs[:,1,:], labels=inputs[:,2,:])\n",
        "      \n",
        "      # Add the loss and batch size to the list:\n",
        "      loss = outputs[0]\n",
        "\n",
        "      losses.append(loss.item())\n",
        "      nums.append(len(xb))\n",
        "\n",
        "      model.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    # Compute the average cost over one epoch:\n",
        "    train_cost = np.sum(np.multiply(losses, nums)) / sum(nums)\n",
        "    train_ppl = torch.exp(torch.tensor(train_cost))\n",
        "    \n",
        "#    print(outputs[0], outputs[1],outputs[2])\n",
        "    # loss_c = torch.nn.CrossEntropyLoss(outputs[0],inputs[:,2,:])\n",
        "    # print(\"loss_c\", loss_c)\n",
        "\n",
        "    # Now run the validation:\n",
        "\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "      losses = []\n",
        "      nums = []\n",
        "\n",
        "      for xb in tqdm(val_dl, desc=\"Validation\"):\n",
        "        inputs = xb.to(device)\n",
        "        outputs = model(inputs[:,0,:], token_type_ids=inputs[:,1,:], labels=inputs[:,2,:])\n",
        "        losses.append(outputs[0].item())\n",
        "        nums.append(len(xb))\n",
        "\n",
        "    val_cost = np.sum(np.multiply(losses, nums)) / sum(nums)\n",
        "    val_ppl = torch.exp(torch.tensor(val_cost))\n",
        "\n",
        "    print('\\n--- Epoch #{} finished --- \\n Training loss: {} \\n Training Perplexity: {} \\n Validation loss: {} \\n Validation Perplexity: {}'.format(i, train_cost, train_ppl, val_cost, val_ppl))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train Model"
      ],
      "metadata": {
        "id": "3LOpwnK-A7Vi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nbo6Nyoe1N7",
        "outputId": "667d2cef-d96f-4d68-bc61-24ba614c9cd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting epoch #0 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 4188/4188 [12:56<00:00,  5.40it/s]\n",
            "Validation: 100%|██████████| 466/466 [00:28<00:00, 16.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Epoch #0 finished --- \n",
            " Training loss: 3.8395223954323825 \n",
            " Training Perplexity: 46.50325896621431 \n",
            " Validation loss: 3.6526239027673704 \n",
            " Validation Perplexity: 38.57575239412499\n",
            "\n",
            "--- Starting epoch #1 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 4188/4188 [12:54<00:00,  5.41it/s]\n",
            "Validation: 100%|██████████| 466/466 [00:28<00:00, 16.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Epoch #1 finished --- \n",
            " Training loss: 3.521841448183652 \n",
            " Training Perplexity: 33.8466980537957 \n",
            " Validation loss: 3.6352521201363097 \n",
            " Validation Perplexity: 37.91140992216956\n",
            "\n",
            "--- Starting epoch #2 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 4188/4188 [12:55<00:00,  5.40it/s]\n",
            "Validation: 100%|██████████| 466/466 [00:28<00:00, 16.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Epoch #2 finished --- \n",
            " Training loss: 3.2692177640176725 \n",
            " Training Perplexity: 26.290765714653727 \n",
            " Validation loss: 3.6078238546492005 \n",
            " Validation Perplexity: 36.88569677577374\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import AdamW\n",
        "\n",
        "# Move the model to the GPU:\n",
        "device = torch.device('cuda:0')\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "# Fine-tune GPT2 for two epochs:\n",
        "optimizer = AdamW(model.parameters())\n",
        "fit(model, optimizer, train_loader, val_loader, epochs=3, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "0R1n9dk34gRh"
      },
      "outputs": [],
      "source": [
        "import torch.nn\n",
        "path1 = \"/content/drive/MyDrive/266Project/gpt2.pt\" #right one\n",
        "\n",
        "# Save\n",
        "torch.save(model, path1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load\n",
        "model = torch.load(path1)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGHsBq2FqL-z",
        "outputId": "38647d09-b4fa-4b0f-9a91-07e66fbac9a6"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50260, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-5): 6 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50260, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ],
      "metadata": {
        "id": "MWnIolpW32xh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Test Perplexity"
      ],
      "metadata": {
        "id": "aziT4umFBEB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate perplexity on test data\n",
        "test_dataset = QuoteDataset('test_data.csv', tokenizer)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "loss_c = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "  losses = []\n",
        "  nums = []\n",
        "\n",
        "  for xb in tqdm(test_loader, desc=\"Test\"):\n",
        "    inputs = xb.to(device)\n",
        "    outputs = model(inputs[:,0,:], token_type_ids=inputs[:,1,:], labels=inputs[:,2,:])\n",
        "    losses.append(outputs[0].item())\n",
        "    nums.append(len(xb))\n",
        "\n",
        "test_cost = np.sum(np.multiply(losses, nums)) / sum(nums)\n",
        "test_ppl = torch.exp(torch.tensor(test_cost))\n",
        "\n",
        "print('\\nTest loss: {} \\n Test Perplexity: {}'.format(test_cost, test_ppl))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgGEJTBk4P86",
        "outputId": "f423d806-baad-4c26-f120-c8757f0b8f17"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Test: 100%|██████████| 517/517 [00:32<00:00, 16.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test loss: 3.601858137193455 \n",
            " Test Perplexity: 36.666302204346806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Bleu & Gleu Scores"
      ],
      "metadata": {
        "id": "COweHCUFBIUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "kDJ4bbKtC2Ic",
        "outputId": "031b99ed-c970-427a-85c7-c248a7301a02"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             quote_context  \\\n",
              "677557   Write a quote about hope from the perspective ...   \n",
              "2173234  Write a quote about test from the perspective ...   \n",
              "1492692  Write a quote about malls from the perspective...   \n",
              "1320974  Write a quote about impression from the perspe...   \n",
              "1254670  Write a quote about heavyweight champion from ...   \n",
              "\n",
              "                                                     quote  \n",
              "677557   If we have the capacity to make mistakes, then...  \n",
              "2173234  Every man has a right to utter what he thinks ...  \n",
              "1492692  I love consumerism, TV culture, shopping malls...  \n",
              "1320974  I want people to have a good impression of Isr...  \n",
              "1254670  If I can be heavyweight champion of boxing, I ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-184daf8f-7a80-4d02-9922-f866041cee20\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>quote_context</th>\n",
              "      <th>quote</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>677557</th>\n",
              "      <td>Write a quote about hope from the perspective ...</td>\n",
              "      <td>If we have the capacity to make mistakes, then...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2173234</th>\n",
              "      <td>Write a quote about test from the perspective ...</td>\n",
              "      <td>Every man has a right to utter what he thinks ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1492692</th>\n",
              "      <td>Write a quote about malls from the perspective...</td>\n",
              "      <td>I love consumerism, TV culture, shopping malls...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1320974</th>\n",
              "      <td>Write a quote about impression from the perspe...</td>\n",
              "      <td>I want people to have a good impression of Isr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1254670</th>\n",
              "      <td>Write a quote about heavyweight champion from ...</td>\n",
              "      <td>If I can be heavyweight champion of boxing, I ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-184daf8f-7a80-4d02-9922-f866041cee20')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-184daf8f-7a80-4d02-9922-f866041cee20 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-184daf8f-7a80-4d02-9922-f866041cee20');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_sample = test.sample(n=400)\n",
        "test_sample.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9Kv-1HlHlSf",
        "outputId": "c7a13644-1ada-4c4d-e2c0-06ca74515ca0"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "JBdmK0sN_NhP"
      },
      "outputs": [],
      "source": [
        "#build the code to evaluate test dataset on model and append decoded results\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.gleu_score import sentence_gleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "# temperature_values = [0.5,1.0,2.0]\n",
        "# no_repeat_ngram_size_values = [2,3]\n",
        "# top_p_values = [0.00,0.75]\n",
        "# top_k_values = [0,10]\n",
        "\n",
        "# #Set1\n",
        "# temperature_values=0.5\n",
        "# no_repeat_ngram_size_values=2\n",
        "# top_p_values=0.00\n",
        "# top_k_values=0\n",
        "\n",
        "# Set2\n",
        "# temperature_values=0.5\n",
        "# no_repeat_ngram_size_values=3\n",
        "# top_p_values=0.75\n",
        "# top_k_values=10\n",
        "\n",
        "#Set3\n",
        "# temperature_values=1\n",
        "# no_repeat_ngram_size_values=3\n",
        "# top_p_values=0.75\n",
        "# top_k_values=10\n",
        "\n",
        "#Set4\n",
        "# temperature_values=1\n",
        "# no_repeat_ngram_size_values=2\n",
        "# top_p_values=0\n",
        "# top_k_values=0\n",
        "\n",
        "#Set5\n",
        "# temperature_values=2\n",
        "# no_repeat_ngram_size_values=2\n",
        "# top_p_values=0\n",
        "# top_k_values=0\n",
        "\n",
        "#Set6\n",
        "temperature_values=2\n",
        "no_repeat_ngram_size_values=3\n",
        "top_p_values=0.75\n",
        "top_k_values=10\n",
        "\n",
        "for i in tqdm(range(10), disable=True):\n",
        "    time.sleep(1)\n",
        "\n",
        "gpt2_quotes = []\n",
        "bleu=[]\n",
        "gleu=[]\n",
        "\n",
        "for i in test_sample.index: \n",
        "    prompt = (test_sample.loc[i, \"quote_context\"])\n",
        "    label = (test_sample.loc[i, \"quote\"])\n",
        "    output_quote = quote_generate(prompt,temperature=a,no_repeat_ngram_size = b,top_p = c, top_k = d)\n",
        "    gpt2_quotes.append(output_quote)\n",
        "\n",
        "    label = label.split()\n",
        "    output_quote = output_quote.split()\n",
        "\n",
        "    bleu.append(sentence_bleu(label, output_quote,smoothing_function=SmoothingFunction().method1))\n",
        "    gleu.append(sentence_gleu(label, output_quote))\n",
        "\n",
        "\n",
        "test_sample['generated_quotes_6'] = gpt2_quotes\n",
        "test_sample['bleu_score_6'] = bleu\n",
        "test_sample['gleu_score_6'] = gleu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_sample"
      ],
      "metadata": {
        "id": "ljIOHy_2QeFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"blue: \",test_sample['bleu_score_1'].mean())\n",
        "print(\"glue: \",test_sample['gleu_score_1'].mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43PBlHqc7q3F",
        "outputId": "7d3b3282-6030-4b63-8427-8a703c0d9070"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "blue:  0.004931791503120119\n",
            "glue:  0.0070939157730375135\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"blue: \",test_sample['bleu_score_2'].mean())\n",
        "print(\"glue: \",test_sample['gleu_score_2'].mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1xDN78nHyuJ",
        "outputId": "a050bb28-e331-4e39-ed4a-54d35b649857"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "blue:  0.005308427125209862\n",
            "glue:  0.0075659000734117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"blue: \",test_sample['bleu_score_3'].mean())\n",
        "print(\"glue: \",test_sample['gleu_score_3'].mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gsvLEwmH-2M",
        "outputId": "a513158b-e662-4f53-e190-61171472c427"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "blue:  0.005163721147192419\n",
            "glue:  0.007534519838958542\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"blue: \",test_sample['bleu_score_4'].mean())\n",
        "print(\"glue: \",test_sample['gleu_score_4'].mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaoaE-uJIA4S",
        "outputId": "947c4ea3-6338-4bec-924c-7408b1cb66ce"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "blue:  0.004906697492896218\n",
            "glue:  0.006864878062376614\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"blue: \",test_sample['bleu_score_5'].mean())\n",
        "print(\"glue: \",test_sample['gleu_score_5'].mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8Ij16otIBu9",
        "outputId": "36409826-16de-4d27-ba3a-776bb6de834f"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "blue:  0.005079563257195825\n",
            "glue:  0.007173620533110315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"blue: \",test_sample['bleu_score_6'].mean())\n",
        "print(\"glue: \",test_sample['gleu_score_6'].mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1REWUnSKIExP",
        "outputId": "d1be6af4-38c1-41d9-8068-9a03f4316ab4"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "blue:  0.004892647699674179\n",
            "glue:  0.006969261834234911\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_sample.to_csv(r'/content/drive/MyDrive/266Project/test_scores.csv', sep=',', mode='w')"
      ],
      "metadata": {
        "id": "PlO9vwD8QwdS"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Generate quote"
      ],
      "metadata": {
        "id": "oB2-_0tg0REd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#customized decoding for distilgpt2 \n",
        "def quote_generate(quote_context,temperature,no_repeat_ngram_size,top_p,top_k,num_beams=5):\n",
        "\n",
        "    context_tkn = tokenizer.additional_special_tokens_ids[0]\n",
        "    quote_tkn = tokenizer.additional_special_tokens_ids[1]\n",
        "\n",
        "    input_ids = [context_tkn] + tokenizer.encode(prompt)\n",
        "\n",
        "    segments = [quote_tkn] * 150\n",
        "    segments[:len(input_ids)] = [context_tkn] * len(input_ids)\n",
        "\n",
        "    input_ids += [quote_tkn]\n",
        "\n",
        "    context = torch.tensor(input_ids, dtype=torch.long, device=device)\n",
        "    context = context.unsqueeze(0)\n",
        "\n",
        "    # Move the model back to the CPU for inference:\n",
        "    #model.to(torch.device('cpu'))\n",
        "    model.to(torch.device('cuda'))\n",
        "\n",
        "    test_output = model.generate(context,\n",
        "                                do_sample=True,   \n",
        "                                min_length=0, \n",
        "                                max_length=50,\n",
        "                                top_k=top_k,                                 \n",
        "                                top_p=top_p,         \n",
        "                                temperature=temperature, \n",
        "                                num_beams = num_beams, \n",
        "                                no_repeat_ngram_size=no_repeat_ngram_size,\n",
        "                                early_stopping=True,\n",
        "                                repetition_penalty=2.0,\n",
        "                                pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "\n",
        "    #decode the output\n",
        "    quote = tokenizer.decode(test_output.squeeze().tolist())\n",
        "    quote = quote.split('<|endoftext|>')[0].split('<quote>')[1]\n",
        "\n",
        "    return quote"
      ],
      "metadata": {
        "id": "Ttf-lqqcBXST"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Write a quote about being headstrong from the perspective of Michelle Williams \"\n",
        "#Write a quote about love from the perspective of Marilyn Monroe\"\n",
        "\n",
        "#best bleu and glue score \n",
        "temperature_values=0.5\n",
        "no_repeat_ngram_size_values=3\n",
        "top_p_values=0.75\n",
        "top_k_values=10\n",
        "\n",
        "output = quote_generate(prompt,temperature=temperature_values,\n",
        "                        no_repeat_ngram_size = no_repeat_ngram_size_values,top_p = top_p_values, top_k = top_k_values)\n",
        "print(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQj4p5hllXf8",
        "outputId": "5ccbdef5-8153-4e47-8432-1e9764fca038"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " I'm not saying I'm going to be an actress, but I'm saying that I'm not.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "I'm not just an actress, but I'm also a part-time storyteller."
      ],
      "metadata": {
        "id": "8QQqC8RoYkaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Baseline Pretrained LLM"
      ],
      "metadata": {
        "id": "kNbbZ-1EVELI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = 'distilgpt2' \n",
        "model = GPT2LMHeadModel.from_pretrained(MODEL_NAME)"
      ],
      "metadata": {
        "id": "ipAV8kNCVMDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_tkn = tokenizer.additional_special_tokens_ids[0]\n",
        "quote_tkn = tokenizer.additional_special_tokens_ids[1]\n",
        "\n",
        "input_ids = [context_tkn] + tokenizer.encode(prompt)\n",
        "\n",
        "segments = [quote_tkn] * 150\n",
        "segments[:len(input_ids)] = [context_tkn] * len(input_ids)\n",
        "\n",
        "input_ids += [quote_tkn]\n",
        "\n",
        "context = torch.tensor(input_ids, dtype=torch.long, device=device)\n",
        "context = context.unsqueeze(0)\n",
        "\n",
        "# Move the model back to the CPU for inference:\n",
        "#model.to(torch.device('cpu'))\n",
        "model.to(torch.device('cuda'))\n",
        "\n",
        "test_output = model.generate(context)\n"
      ],
      "metadata": {
        "id": "fBCB7l-ZVkDN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Qv2MZ79S0Fv6",
        "aziT4umFBEB3"
      ],
      "toc_visible": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}